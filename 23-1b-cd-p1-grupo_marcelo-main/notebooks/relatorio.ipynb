{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Marcelo da Costa Poltronieri\n",
    "\n",
    "Nome: Pedro Nery Affonso dos Santos\n",
    "\n",
    "Nome: Victor de Almeida Cunha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\Victor Cunha\\Desktop\\Atividades\\C-Dados\\23-1b-cd-p1-grupo_marcelo\\notebooks\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/dados.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avaliacao</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A insatisfação com o trabalho, a importância d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nossa, que livro ruim. Muito mais muito prolix...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Não vale a pena, é uma ofensa aos Potterfanati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O mais impressionante é que os personagens do ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Olavo será um dos responsáveis pela destruição...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Avaliacao  Target\n",
       "0  A insatisfação com o trabalho, a importância d...       1\n",
       "1  Nossa, que livro ruim. Muito mais muito prolix...       0\n",
       "2  Não vale a pena, é uma ofensa aos Potterfanati...       0\n",
       "3  O mais impressionante é que os personagens do ...       1\n",
       "4  Olavo será um dos responsáveis pela destruição...       2"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avaliacao</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pense naquele livro que no caso de estar a pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muito bom o livro e recomendo, é um verdadeiro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O livro cumpre muito bem sua proposta, gera bo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Este livro é um clássico. Simplesmente maravil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Este clássico é mágico e fascinante em seus en...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Avaliacao  Target\n",
       "0  Pense naquele livro que no caso de estar a pro...       1\n",
       "1  Muito bom o livro e recomendo, é um verdadeiro...       1\n",
       "2  O livro cumpre muito bem sua proposta, gera bo...       1\n",
       "3  Este livro é um clássico. Simplesmente maravil...       1\n",
       "4  Este clássico é mágico e fascinante em seus en...       1"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu assunto e o que considerou como relevante ou não relevante na classificação dos tweets (Target).\n",
    "\n",
    "O assunto escolhido pelo grupo foi o de livros vendidos pela plataforma da Amazon. Para que as avaliações possam realmente refletir o conteúdo do livro, ou seja, o sentimento popular sobre a obra lida, foram escolhidos três critérios: comentários que elaboram críticas **positivas** ao **conteúdo** do livro (1), comentários **negativos** em relação ao **conteúdo** do livro (0) e, por último, comentários **não** referentes ao **conteúdo do livro ou resumos da obra**, como, por exemplo, reclamações sobre a entrega ou sobre traduções e edições. (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Breve explicação do Classificador Naive-Bayes:**\n",
    "\n",
    "O objetivo do projeto consiste em montar um classificador probabilístico capaz de escolher corretamente, dada uma certa frase, entre as três opções de variável Target expostos anteriormente (1, 2, ou 0). Ou seja, aquilo que se deseja que o bot faça é calcular, para cada comentário contido na planilha de Excel, as seguintes probabilidades condicionais: **P(0 | frase)**, **P(1 | frase)** e **P(2 | frase)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular tais probabilidades, o robô será programado de tal forma que seja capaz de analisar as **frequências de cada palavra na frase** e escolher entre a maior das três. Ao final da frase, deseja-se que o bot tome uma decisão: afinal, aquela frase tem maior probabilidade de ser uma análise crítica positiva(1), negativa (0), ou nem se refere ao conteúdo do livro (2)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a montagem do robô, deseja-se descobrir, por meio do comando pd.crosstab(), a taxa de acertos do robô. Em relação àquilo que era esperado dele, qual foi a eficiência do código quando se deparou com frases classificadas como 1, 0 e 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A seguir, é possível visualizar a montagem do Classificador Naive-Bayes em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, deseja-se fornecer ao classificador as frequências relativas de cada palavra em frases que sejam positivas, negativas ou irrelevantes. Assim, dado que já foi feita uma classificação manual pelo grupo na planilha de Excel, faz-se necessário realizar quatro filtros das frases (dado que também será necessário mais tarde treinar o robô, sem acesso às respostas) por meio do comando **.loc[]** e guardá-los em suas respectivas variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os filtros prontos e guardados, coloca-se todas as frases em seguida em uma lista por meio do comando **.values.tolist()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as avaliações positivas, negativas, irrelevantes e o total em listas\n",
    "\n",
    "positivo = train.loc[train['Target']==1,['Avaliacao']]\n",
    "negativo = train.loc[train['Target']==0,['Avaliacao']]\n",
    "irrelevante = train.loc[train['Target']==2,['Avaliacao']]\n",
    "treinamento = train.loc[:,['Avaliacao']]\n",
    "\n",
    "positivo_list = positivo['Avaliacao'].values.tolist()\n",
    "negativos_list = negativo['Avaliacao'].values.tolist()\n",
    "irrelevantes_list = irrelevante['Avaliacao'].values.tolist()\n",
    "treinamento_list = treinamento['Avaliacao'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já temos as frases devidamente divididas e guardadas em listas com suas respectivas classificações, precisamos fazer um **.split()** para obter as palavras de cada frase. Entretanto, antes disso, como muitos dos comentários na base de dados apresentam elementos que podem atrapalhar na análise do bot (pontos de interrogação, exclamação, vírgulas, etc), devemos retirá-los. Para isso, usaremos um loop em **while** e a **função cleanup** definida anteriormente para guardar as frases, agora limpas, em novas listas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando todas as frases:\n",
    "\n",
    "r = 0\n",
    "positivos_list_clean = []\n",
    "\n",
    "ir = 0\n",
    "irrelevantes_list_clean = []\n",
    "\n",
    "n = 0\n",
    "negativos_list_clean = []\n",
    "\n",
    "t = 0\n",
    "treinamento_list_clean = []\n",
    "\n",
    "while r<len(positivo_list):\n",
    "    positivos_list_clean.append(cleanup(positivo_list[r]))\n",
    "    r += 1\n",
    "\n",
    "while ir<len(irrelevantes_list):\n",
    "    irrelevantes_list_clean.append(cleanup(irrelevantes_list[ir]))\n",
    "    ir += 1\n",
    "\n",
    "while n<len(negativos_list):\n",
    "    negativos_list_clean.append(cleanup(negativos_list[n]))\n",
    "    n += 1\n",
    "\n",
    "while t<len(treinamento_list):\n",
    "    treinamento_list_clean.append(cleanup(treinamento_list[t]))\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, por meio de um laço **for**, faz-se a separação de palavra em palavra para cada uma das frases das listas de comentários positivios, negativos, irrelevantes e de treinamento. Cria-se, em seguida, um Data Frame contendo todas as palavras nas listas. O Data Frame nos interessa, pois ele irá fornecer ao bot as frequências relativas de cada palavra por meio do comando **.value_counts(normalize=True)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as frases em palavras\n",
    "\n",
    "pos_palavras = []\n",
    "irrel_palavras = []\n",
    "neg_palavras = []\n",
    "todas_palavras = []\n",
    "\n",
    "for frase in positivos_list_clean:\n",
    "    palavras = frase.split()\n",
    "    for palavra in palavras:\n",
    "        pos_palavras.append(palavra)\n",
    "\n",
    "# Após a separação, cria-se um Dataframe com todas as palavras de tal divisão\n",
    "\n",
    "dfpos = pd.Series(pos_palavras)\n",
    "\n",
    "for frase in irrelevantes_list_clean:\n",
    "    palavras = frase.split()\n",
    "    for palavra in palavras:\n",
    "        irrel_palavras.append(palavra)\n",
    "\n",
    "dfirrel = pd.Series(irrel_palavras)\n",
    "\n",
    "for frase in negativos_list_clean:\n",
    "    palavras = frase.split()\n",
    "    for palavra in palavras:\n",
    "        neg_palavras.append(palavra)\n",
    "\n",
    "dfneg = pd.Series(neg_palavras)\n",
    "\n",
    "for frase in treinamento_list_clean:\n",
    "    palavras = frase.split()\n",
    "    for palavra in palavras:\n",
    "        todas_palavras.append(palavra)\n",
    "\n",
    "dfall = pd.Series(todas_palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os Data Frames obtidos, é possível descobrir por meio dos seus tamanhos as probabilidade de uma palavra ser positiva, irrelevante ou negativa, já que temos o espaço amostral no DF contendo todas as palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de ser uma palavra positiva: 0.44265075962345046\n",
      "Probabilidade de ser uma palavra irrelevante: 0.26170192935035885\n",
      "Probabilidade de ser uma palavra negativa: 0.2956473110261907\n"
     ]
    }
   ],
   "source": [
    "# Análise da probabilidade de uma palavra ser positiva, negativa ou irrelevante\n",
    "\n",
    "P = len(dfpos)/len(dfall)\n",
    "IR = len(dfirrel)/len(dfall)\n",
    "N = len(dfneg)/len(dfall)\n",
    "\n",
    "print(f\"Probabilidade de ser uma palavra positiva: {P}\")\n",
    "print(f\"Probabilidade de ser uma palavra irrelevante: {IR}\")\n",
    "print(f\"Probabilidade de ser uma palavra negativa: {N}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, a fim de fazer o bot classificar, será necessário usar a **Suavização de LaPlace**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Suavização de LaPlace é uma técnica utilizada para lidar com o problema de frequências zero em um conjunto de dados. \n",
    "Ela é aplicada adicionando-se um valor constante a todas as contagens de cada categoria antes de calcular as probabilidades. \n",
    "No contexto do projeto, ela é necessária para evitar que o bot calcule a probabilidade de uma palavra dada uma categoria como zero quando a palavra não aparece naquela categoria na base de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso ocorre porque, sem a suavização, a probabilidade seria igual a zero, o que afetaria negativamente a classificação do bot. Ao adicionar uma constante 1, por exemplo, a todas as contagens de cada categoria, a suavização de LaPlace garante que as probabilidades calculadas pelo bot sejam mais confiáveis e precisas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montagem do classificador com Suavização de LaPlace\n",
    "\n",
    "def classificador(texto):\n",
    "    clear = cleanup(texto.lower())\n",
    "    split = clear.split()\n",
    "    r1 = 1\n",
    "    ir1 = 1\n",
    "    n1 = 1\n",
    "    pos = dfpos.value_counts()\n",
    "    irrel = dfirrel.value_counts()\n",
    "    neg = dfneg.value_counts()\n",
    "    for word in split:\n",
    "        if word in pos:\n",
    "            r = pos[word]\n",
    "        else:\n",
    "            r = 0\n",
    "        if word in irrel:\n",
    "            ir = irrel[word]\n",
    "        else:\n",
    "            ir = 0\n",
    "        if word in neg:\n",
    "            n = neg[word]\n",
    "        else:\n",
    "            n = 0\n",
    "\n",
    "#Suavização de Laplace\n",
    "    r1 = r1*((r+1)/((len(dfpos))+len(dfall.value_counts())))\n",
    "    ir1 = ir1*((ir+1)/((len(dfirrel))+len(dfall.value_counts())))\n",
    "    n1 = n1*((n+1)/((len(dfneg))+ len(dfall.value_counts())))\n",
    "    pp = r1*P\n",
    "    pir = ir1*IR\n",
    "    pn = n1*N\n",
    "\n",
    "    l = [pp,pir,pn]\n",
    "    if pp == max(l):\n",
    "        return 1\n",
    "    if pir == max(l):\n",
    "        return 2\n",
    "    if pn == max(l):\n",
    "        return 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a função do classificador agora já definida, utiliza-se um laço **for** que percorra todas as frases na planilha de testes do Excel e construa uma lista com todas as categorias que o bot atribui a cada frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 1, 1, 2, 1, 1, 2, 1, 2, 1, 0, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 2, 0, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 0, 2, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 1, 0, 2, 2, 1, 0, 2, 1, 1, 1, 1, 1, 1, 2, 1, 0, 0, 1, 1, 1, 2, 2, 1, 1, 1, 1, 0, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 2, 0, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 0, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 0, 0, 0, 0, 1, 2, 1, 1, 2, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 0, 1, 2, 1, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 2, 1, 2, 1, 1, 1, 2, 2, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 2, 1, 0, 1, 0, 1, 2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 0, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 2, 2, 0, 1, 1, 0, 2, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 0, 1, 1, 2, 0, 0, 1, 1, 2, 0, 0, 0, 1, 1, 2, 2, 1, 2, 1, 0, 1, 2, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Aplicação do classificador\n",
    "\n",
    "i=0\n",
    "l=[]\n",
    "\n",
    "for review in test['Avaliacao']:\n",
    "    aval = classificador(review)\n",
    "    l.append(aval)\n",
    "    i+=1\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de imprimir a lista, basta jogar os dados obtidos em um **crosstab** com os dados originais para analisar os acertos do classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.180301</td>\n",
       "      <td>23.038397</td>\n",
       "      <td>4.841402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.841402</td>\n",
       "      <td>29.716194</td>\n",
       "      <td>3.839733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.338898</td>\n",
       "      <td>13.021703</td>\n",
       "      <td>9.181970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0          0          1         2\n",
       "Target                               \n",
       "0       8.180301  23.038397  4.841402\n",
       "1       4.841402  29.716194  3.839733\n",
       "2       3.338898  13.021703  9.181970"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analisando a precisão do classificador\n",
    "\n",
    "pd.crosstab(test['Target'], l, normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender quais foram os acertos, basta olhar a partir da posição (0,0): isso significa que tanto o Target quanto o classificador deram valor 0. Em (1,1), ambas atribuíram valor 1 e em (2,2), valor 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classificador funciona como proposto: o código está funcional e não há nenhum erro de repetição e de sintaxe. Ao anallisar, podemos perceber que o classificador é mais preciso para as avaliações positivas, mantendo a maior porcentagem (aproximadamente 29,7%). Porém, o mesmo não pode ser dito pelas avaliações negativas ou irrelevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao analisar o código e as avaliações manualmente, percebemos que a maioria dos erros não se deve ao código **(possivelmente uma futura iteração com detalhamento maior no código poderia mitigar alguns problemas, mas não foi o analisado)**, mas sim às próprias avaliações dos usuários."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso se dá principalmente pois, de acordo com o critério de análise selecionado, **as avaliações irrelevantes são aquelas que não se referem ao livro, mas sim à entrega e qualidade do material físico, podendo ser tanto avaliações positivas ou negativas**. Por conta disso, algumas avaliações que originalmente eram irrelevantes **podem acabar assumindo o papel de avaliações positivas ou negativas**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um outro motivo, por fim, é um fora do controle do próprio bot: **a incapacidade de captar ironias e sátiras**. Algumas avaliações negativas utilizaram ironias e sátiras para dizer que o conteúdo do livro era ruim, assim prejudicando a análise do classificador. Por conta disso, **algumas avaliações negativas acabaram sendo positivas**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma análise extra que pode ser considerada como um fator da imprecisão do bot é o fato de que **críticas e análises sem ditar uma avaliação com opinião foram consideradas irrelevantes**. Nestes casos, o bot pode ter assumido tais como avaliações positivas ou negativas. O mesmo se aplica para avaliações positivas e/ou negativas que possuíam críticas a certos aspectos do livro em questão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em uma futura iteração, o código poderia levar em conta padrões em algumas avaliações irrelevantes e nos casos irônicos para poder avaliar corretamente aquelas que foram avaliadas erroneamente. Além disso, poderiam ser implementadas algumas análises de pontuação para melhorar a análise do bot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
